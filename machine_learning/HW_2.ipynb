{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Блок практики"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "ed1f9ce7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Давайте попробуем оценить, насколько и вправду гномы оказались умными и осведомленными в области построения различных моделей машинного обучения, и найдем, насколько сильно их модели ошибаются на наших данных!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427430c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В начале посчитайте **MSE** модели. Для этого нужно посчитать квадратичное отклонение на каждом объекте, а потом просто усредниться! Полезно иметь формулу перед глазами.\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_i^n (a(x_i)-y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6caf40d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE первой модели равно: 99994\n",
      "MSE второй модели равно: 124936\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "error_1 = ((df['prediction_1'] - df['trip_duration'])**2).mean()\n",
    "error_2 = ((df['prediction_2'] - df['trip_duration'])**2).mean()\n",
    "\n",
    "print(f\"MSE первой модели равно: {int(error_1)}\")\n",
    "print(f\"MSE второй модели равно: {int(error_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468537d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6cdf69",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Видно, что у MSE достаточно большой порядок. Как мы и говорили, глазам куда будет приятнее, если мы будем считать **RMSE**:\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_i^n (a(x_i)-y_i)^2}|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab696a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE первой модели равно: 316\n",
      "RMSE второй модели равно: 353\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "print(f\"RMSE первой модели равно: {int(error_1**(1/2))}\")\n",
    "print(f\"RMSE второй модели равно: {int(error_2**(1/2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e9f45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Что можете сказать про модели первого и второго гнома? Чья оказалась лучше с точки зрения **MSE**? \n",
    "\n",
    "*Ответ: с точки зрения MSE/RMSE модель первого гнома оказалась лучше. Как минимум, это значит, что если обе модели очень сильно ошибаются на какой-то группе объектов, то у первого эта ошибка не такая уж и гигантская: например, 8000 против 10000. Как раз-таки это связано с крайней чувствительностью MSE к большим ошибкам. Чем дальше предсказание от ответа, тем метрика принимает все более ужасающие значения.\n",
    "Но это не значит, что в среднем предсказания первой модели на всех объектах лучше во всех смыслах.*\n",
    "\n",
    "Давайте теперь замерим значения средней абсолютной ошибки, то есть **MAE**:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_i^n |a(x_i)-y_i|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3a5a6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e685567",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE первой модели равно: 300\n",
      "MAE второй модели равно: 281\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "absolute_error_1 = (abs(df['prediction_1'] - df['trip_duration'])).mean()\n",
    "absolute_error_2 = (abs(df['prediction_2'] - df['trip_duration'])).mean()\n",
    "\n",
    "print(f\"MAE первой модели равно: {int(absolute_error_1)}\")\n",
    "print(f\"MAE второй модели равно: {int(absolute_error_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d6878",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e1842",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Если бы Вас попросили выбрать лучшую модель среди предложенных, на какой Вы бы остановились? Если брать за финальную метрику **MAE**, то поменяли бы Вы решение?\n",
    "\n",
    "Конечно! Мы наблюдаем ту самую ситуацию, когда, имея 2 разные модели с разными предсказаниями, финальный выбор однозначно сделать нельзя, например, сказав *\"Первая модель в среднем и в общем лучше второй!\"*. **Нет!** Все зависит от формы ошибки, которую мы выбираем. Иными словами, от вида той самой функции, которая наказывает наши модели и замеряет качество их прогнозов.\n",
    "\n",
    "Ситуация, когда **MAE** и **MSE**, выбирая между 2-х,  указывают на разные модели, знакома нам еще из лекции. \n",
    "\n",
    "Такое может происходить, когда в одной из моделей ошибка, в среднем, независимо от порядка чисел, чуть-чуть получше, чем во второй. Но при этом если первая модель и ошибается, то куда суровее второй. \n",
    "\n",
    "Представьте: Петя и Миша играют в дартс. Петя в 9/10 случаев попадает в яблочко, но каждый 10-ый раз кидает дротик в потолок. Миша же, хоть и не так часто забрасывает в центр (всего 6/10), но при этом, оставшиеся 4 попытки реализует не совсем фатально: попадает всего-лишь немного дальше яблочка. \n",
    "\n",
    "В таком выдуманном сценарии Петя будет лучше с точки зрения **MAE**, а Миша - с точки зрения **MSE**, так как не допускает фатальных ошибок, хоть и в среднем набирает меньше очков. \n",
    "\n",
    "Давайте и вправду убедимся в том, что фатальных ошибок у второй модели больше. \n",
    "\n",
    "Посчитайте, в скольки случаях предсказания откланяются от ответа более, чем на **500**, для первой и второй моделей!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c583838",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество отклонений >= 500 от верного ответа для первой модели равно: 33061\n",
      "Количество отклонений >= 500 от верного ответа для второй модели равно: 228789\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "counter_1 = sum(abs(df['prediction_1'] - df['trip_duration']) >= 500)\n",
    "counter_2 = sum(abs(df['prediction_2'] - df['trip_duration']) >= 500)\n",
    "\n",
    "print(f\"Количество отклонений >= 500 от верного ответа для первой модели равно: {counter_1}\")\n",
    "print(f\"Количество отклонений >= 500 от верного ответа для второй модели равно: {counter_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba25f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Полученные результаты кажутся нам логичными: как и подмечали ранее, первая модель скорее лучше в смысле \"суровых ошибок\", когда у второй среднее абсолюнтное отклонение прогноза от действительности поменьше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e818d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Несимметричные метрики**\n",
    "\n",
    "Зачастую, чтобы выбрать среди всего многообразия моделей, мы можем использовать несимметричные метрики. \n",
    "\n",
    "**MSE** и **MAE** относятся к симметричным. Они одинаково наказывают модель как за перепредсказание, так и за недопредсказание. Ошибки *+2* и *-2* переводятся **MSE** и **MAE** в одинаковую меру: **4** в первом случае и **2** во втором.\n",
    "\n",
    "В действительности же, можно придумать целый ряд задач, когда лучше выбирать несимметричную метрику.\n",
    "\n",
    "Представьте, что мы - дистрибьютор инсулина, и нам нужно построить модель, которая оптимизирует поставки. В таком случае, кажется, что поставить лекарства на 2 единицы больше и на 2 единицы меньше - совершенно разные сценарии и разная интерпретация катастрофичности ошибки. \n",
    "\n",
    "В первом случае мы можем потерять немного прибыли, а во втором - лишить пациента жизненноважного лекарства. Поэтому хотелось бы научиться еще и по-разному оценивать *недо- и перепредсказания*. Для этого как раз-таки и используют несимметричные метрики! Одну из них предлагаю посчитать Вам ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15fe16",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Рассчитайте **RMSLE**. Придумайте, как проверить характер несимметричности данной метрики: за что она наказывает больше - за перепредсказания или за недопредсказания? Это нужно будет в тестовом теоретическом задании.\n",
    "\n",
    "$$\n",
    "\\text{RMSLE}(X, y, a) = \\sqrt{\\frac{1}{\\ell}\\sum_{i=1}^{\\ell} \\big(\\log{(y_i + 1)} - \\log{(a(x_i) + 1)}\\big)^2}\n",
    "$$\n",
    "\n",
    "Для взятия логарифма используйте библиотеку **math**\n",
    "\n",
    "P.S. Очевидно, что для некоторых отрицательных предсказаний, формула не будет работать, так как логарифм от отрицательных значений взять нельзя. Поэтому давайте подкорректируем наши прогнозы: все отрицательные числа переведем в нули (лучше уж в нашей задаче предсказать *ноль секунд*, чем *минус 100 секунд*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe86f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1d2c97c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n",
    "df['prediction_1'] = df['prediction_1'].apply(lambda x: max(x, 0))\n",
    "df['prediction_2'] = df['prediction_2'].apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59041f3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка RMSLE при недопредсказании: 0.104\n",
      "Ошибка RMSLE при перепредсказании: 0.094\n"
     ]
    }
   ],
   "source": [
    "### Чтобы понять, за что модель штрафует больше, проделаем следующий фокус:\n",
    "### Пусть истинное значение таргета равно 100\n",
    "### Одна из моделей предсказана 110\n",
    "### А вторая 90, замерим, где ошибка будет больше:\n",
    "\n",
    "from math import log\n",
    "\n",
    "under_estimating = ((log(90+1)-log(100+1))**2)**(1/2)\n",
    "\n",
    "over_estimating = ((log(110+1)-log(100+1))**2)**(1/2)\n",
    "\n",
    "print(f\"Ошибка RMSLE при недопредсказании: {round(under_estimating, 3)}\")\n",
    "print(f\"Ошибка RMSLE при перепредсказании: {round(over_estimating, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac500e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как видно, RMSLE больше штрафует за недопредсказание!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6036d1ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE первой модели равно: 0.5537581774590482\n",
      "RMSLE второй модели равно: 1.5564340528341787\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "\n",
    "msle_1 = (((df['prediction_1'] + 1).apply(log) - (df['trip_duration'] + 1).apply(log))**2).mean()\n",
    "msle_2 = (((df['prediction_2'] + 1).apply(log) - (df['trip_duration'] + 1).apply(log))**2).mean()\n",
    "\n",
    "print(f\"RMSLE первой модели равно: {msle_1**(1/2)}\")\n",
    "print(f\"RMSLE второй модели равно: {msle_2**(1/2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b5055",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посчитайте, для какого количества объектов первая модель сделала перепредсказания и недопредсказания.\n",
    "\n",
    "P.S. оставьте колонку с предсказанием такой, какой она оказалась после замены отрицательных значений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5696d81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7094a386",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания первой модели оказались больше действительных в 1456721 случаях\n",
      "Предсказания первой модели оказались меньше действительных в 1923 случаях\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "over_predicted_1 = sum(df['prediction_1'] - df['trip_duration'] > 0)\n",
    "\n",
    "under_predicted_1 = sum(df['prediction_1'] - df['trip_duration'] < 0)\n",
    "\n",
    "print(f\"Предсказания первой модели оказались больше действительных в {over_predicted_1} случаях\")\n",
    "print(f\"Предсказания первой модели оказались меньше действительных в {under_predicted_1} случаях\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec4a03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ba7ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Аналогично для второй модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10c76594",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания второй модели оказались больше действительных в 811778 случаях\n",
      "Предсказания второй модели оказались меньше действительных в 646866 случаях\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "over_predicted_2 = sum(df['prediction_2'] - df['trip_duration'] > 0)\n",
    "\n",
    "under_predicted_2 = sum(df['prediction_2'] - df['trip_duration'] < 0)\n",
    "\n",
    "print(f\"Предсказания второй модели оказались больше действительных в {over_predicted_2} случаях\")\n",
    "print(f\"Предсказания второй модели оказались меньше действительных в {under_predicted_2} случаях\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcdd78",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Сравните две модели заново. Согласуется ли полученный результат с подсчетом **RMSLE** ранее?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3c5942",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Да, согласуется! С точки зрения RMSLE, первая модель лучше. Мы знаем, что RMSLE более чувствителен к недопредсказанием, чем перепредсказаниям. При этом видно, что первая модель и вправду ошибалась чаще в бОльшую сторону, чем в мЕньшую."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}